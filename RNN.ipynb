{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "text = \"messi is the best\"\n",
        "words = text.split()\n",
        "\n",
        "\n",
        "if len(words) != 4:\n",
        "    print(f\"Error: The text must contain exactly 4 words. This text has {len(words)} words.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "vocab = sorted(list(set(words)))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
        "\n",
        "print(f\"Vocabulary ({vocab_size} words): {vocab}\")\n",
        "print(f\"Word to Index: {word_to_ix}\")\n",
        "\n",
        "\n",
        "def word_to_one_hot(word, vocab_size, word_to_ix_map):\n",
        "    vector = np.zeros((vocab_size, 1))\n",
        "    if word in word_to_ix_map:\n",
        "        vector[word_to_ix_map[word]] = 1\n",
        "    return vector\n",
        "\n",
        "\n",
        "hidden_size = 5\n",
        "\n",
        "W_xh = np.random.randn(hidden_size, vocab_size) * 0.1\n",
        "W_hh = np.random.randn(hidden_size, hidden_size) * 0.1\n",
        "W_ho = np.random.randn(vocab_size, hidden_size) * 0.1\n",
        "\n",
        "\n",
        "\n",
        "input_words = words[:3]\n",
        "target_word = words[3]\n",
        "\n",
        "print(f\"\\nProcessing sequence: {' '.join(input_words)}\")\n",
        "print(f\"Target word: '{target_word}'\")\n",
        "\n",
        "h = np.zeros((hidden_size, 1))\n",
        "print(f\"Initial hidden state:\\n{h.T}\\n\")\n",
        "\n",
        "\n",
        "word = input_words[0]\n",
        "print(f\"Processing word: '{word}'\")\n",
        "x = word_to_one_hot(word, vocab_size, word_to_ix)\n",
        "\n",
        "\n",
        "h = np.dot(W_hh, h) + np.dot(W_xh, x)\n",
        "\n",
        "\n",
        "print(f\"Hidden state after '{word}':\\n{h.T}\\n\")\n",
        "\n",
        "\n",
        "word = input_words[1]\n",
        "print(f\"Processing word: '{word}'\")\n",
        "x = word_to_one_hot(word, vocab_size, word_to_ix)\n",
        "\n",
        "\n",
        "h = np.dot(W_hh, h) + np.dot(W_xh, x)\n",
        "\n",
        "print(f\"Hidden state after '{word}':\\n{h.T}\\n\")\n",
        "\n",
        "\n",
        "word = input_words[2]\n",
        "print(f\"Processing word: '{word}'\")\n",
        "x = word_to_one_hot(word, vocab_size, word_to_ix)\n",
        "\n",
        "\n",
        "h = np.dot(W_hh, h) + np.dot(W_xh, x)\n",
        "\n",
        "print(f\"Hidden state after '{word}' (Final Hidden State):\\n{h.T}\\n\")\n",
        "\n",
        "\n",
        "print(\"Predicting next word using final hidden state...\")\n",
        "\n",
        "\n",
        "output_scores = np.dot(W_ho, h)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "prediction_probs = softmax(output_scores)\n",
        "\n",
        "\n",
        "predicted_index = np.argmax(prediction_probs)\n",
        "predicted_word = ix_to_word[predicted_index]\n",
        "\n",
        "print(f\"Output scores over vocabulary:\\n{output_scores.T}\")\n",
        "print(f\"\\nProbability distribution:\\n{prediction_probs.T}\")\n",
        "print(f\"\\nPredicted word (index {predicted_index}): {predicted_word}\")\n",
        "print(f\"Actual target word: {target_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZUXBIMWtd49",
        "outputId": "9d7fc857-89a5-4316-dc82-f06f23370fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (4 words): ['best', 'is', 'messi', 'the']\n",
            "Word to Index: {'best': 0, 'is': 1, 'messi': 2, 'the': 3}\n",
            "\n",
            "Processing sequence: messi is the\n",
            "Target word: 'best'\n",
            "Initial hidden state:\n",
            "[[0. 0. 0. 0. 0.]]\n",
            "\n",
            "Processing word: 'messi'\n",
            "Hidden state after 'messi':\n",
            "[[-0.10458696 -0.19936731 -0.06254328 -0.02804806 -0.08536691]]\n",
            "\n",
            "Processing word: 'is'\n",
            "Hidden state after 'is':\n",
            "[[-0.29557349  0.08485126 -0.07730034  0.00339084 -0.02675319]]\n",
            "\n",
            "Processing word: 'the'\n",
            "Hidden state after 'the' (Final Hidden State):\n",
            "[[ 0.16440635 -0.04243028 -0.00233541 -0.01850637  0.02633376]]\n",
            "\n",
            "Predicting next word using final hidden state...\n",
            "Output scores over vocabulary:\n",
            "[[-0.00843863 -0.02166293 -0.0147099   0.00943791]]\n",
            "\n",
            "Probability distribution:\n",
            "[[0.2500845  0.24679908 0.24852106 0.25459535]]\n",
            "\n",
            "Predicted word (index 3): the\n",
            "Actual target word: best\n"
          ]
        }
      ]
    }
  ]
}